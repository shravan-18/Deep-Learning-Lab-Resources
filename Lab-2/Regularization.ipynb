{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Dependencies and Ignore Warnings**"
      ],
      "metadata": {
        "id": "laG4hllP73j5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yLhHBd3p7orX"
      },
      "outputs": [],
      "source": [
        "# **Import Libraries and Define Dataset**\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.regularizers import l1, l2\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import warnings module to filter out any warning messages for a cleaner output.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and Preprocess the Dataset**"
      ],
      "metadata": {
        "id": "8MEGolLw8DHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Print shapes of the data to understand the structure\n",
        "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "_4xvMDdK8DtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a model with Dropout**"
      ],
      "metadata": {
        "id": "2gc0eal-8Jse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Define Model with Dropout**\n",
        "\n",
        "def create_model_dropout():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "tNJHqChd8LRO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define the Model with L1 Regularization**"
      ],
      "metadata": {
        "id": "ETu9fcsa8SDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Define Model with L1 Regularization**\n",
        "\n",
        "def create_model_l1():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', kernel_regularizer=l1(0.01), input_shape=(X_train.shape[1],)),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l1(0.01)),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "DfG-2z1q8NmU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define the Model with L2 Regularization**"
      ],
      "metadata": {
        "id": "may1Utfy8QtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Define Model with L2 Regularization**\n",
        "\n",
        "def create_model_l2():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "o8z8qbLd8Noh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and evaluate models**"
      ],
      "metadata": {
        "id": "bvG2dASd8UWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Train and Evaluate Models**\n",
        "\n",
        "def train_and_evaluate_model(model_func, X_train, y_train, X_test, y_test, epochs=30):\n",
        "    model = model_func()\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32, verbose=0)\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score\n",
        "\n",
        "# Train and evaluate model 1\n",
        "dropout_history, dropout_score = train_and_evaluate_model(create_model_dropout, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "toAUfPtA8WPt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate model 2\n",
        "l1_history, l1_score = train_and_evaluate_model(create_model_l1, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "m6KHtJ7h9VqJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate model 3\n",
        "l2_history, l2_score = train_and_evaluate_model(create_model_l2, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "A16uoPyT9Vwu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot Training and Validation Loss**"
      ],
      "metadata": {
        "id": "4wOw0EMq8YkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Plot Training and Validation Loss**\n",
        "\n",
        "def plot_history(histories, title):\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    for label, history in histories.items():\n",
        "        plt.plot(history.history['loss'], label=f'{label} Loss')\n",
        "        plt.plot(history.history['val_loss'], label=f'{label} Val Loss')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot loss curves\n",
        "plot_history({\n",
        "    'Dropout': dropout_history,\n",
        "    'L1 Regularization': l1_history,\n",
        "    'L2 Regularization': l2_history\n",
        "}, 'Training and Validation Loss for Different Regularization Techniques')\n"
      ],
      "metadata": {
        "id": "ZhONr0Ps8YLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **Print the final evaluation scores**\n",
        "\n",
        "print(f\"Dropout Model - Test Loss: {dropout_score[0]}, Test Accuracy: {dropout_score[1]}\")\n",
        "print(f\"L1 Regularization Model - Test Loss: {l1_score[0]}, Test Accuracy: {l1_score[1]}\")\n",
        "print(f\"L2 Regularization Model - Test Loss: {l2_score[0]}, Test Accuracy: {l2_score[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSd_XxQ38djg",
        "outputId": "9290962d-23da-4478-afa8-9ea94708c2bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropout Model - Test Loss: 0.0720161497592926, Test Accuracy: 0.9736841917037964\n",
            "L1 Regularization Model - Test Loss: 0.1884739249944687, Test Accuracy: 0.9824561476707458\n",
            "L2 Regularization Model - Test Loss: 0.10948669165372849, Test Accuracy: 0.9912280440330505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inferences from the plots**\n",
        "### Dropout Regularization:\n",
        "\n",
        "- The training loss and validation loss for the Dropout model are both quite low compared to the other models.\n",
        "- The Dropout model has less overfitting as the training and validation losses are closer to each other.\n",
        "- It converges quickly and maintains a lower loss throughout the epochs.\n",
        "\n",
        "### L1 Regularization:\n",
        "\n",
        "- The training loss for the L1 regularization model starts higher and decreases steadily, but it remains higher than the Dropout model.\n",
        "- The validation loss for the L1 regularization model is also high compared to Dropout.\n",
        "- The gap between the training and validation loss indicates more overfitting compared to Dropout.\n",
        "\n",
        "### L2 Regularization:\n",
        "\n",
        "- Similar to the L1 model, the L2 regularization model starts with a high training loss which decreases steadily.\n",
        "- The validation loss for the L2 model is closer to its training loss compared to L1, suggesting it performs slightly better in terms of generalization than L1 but not as well as Dropout.\n",
        "\n",
        "### Key Points:\n",
        "\n",
        "- **Overfitting**: Models with higher gaps between training and validation losses are overfitting more. In this case, L1 regularization appears to overfit more compared to L2 and Dropout.\n",
        "- **Model Performance**: The Dropout model outperforms both L1 and L2 regularization models in terms of both training and validation losses.\n",
        "- **Regularization Effectiveness**: Dropout seems to be the most effective regularization technique for achieving the lowest loss and best balance between training and validation performance. However, L2 regularization achieves the highest test accuracy, indicating that it is also a very effective technique for this dataset and model architecture.\n",
        "- **Test Accuracy and Loss**: The test results show that while L2 regularization achieves the highest accuracy, Dropout regularization provides a good balance of low loss and high accuracy, and L1 regularization, though effective, shows higher loss compared to the other methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "shoK7ZyN9x8_"
      }
    }
  ]
}