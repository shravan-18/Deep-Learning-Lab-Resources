{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Face Recognition Using Convolutional Neural Networks**\n",
        "\n",
        "#### In today's lab, we'll be implementing image classification using transfer learning with two popular CNN architectures using Transfer Learning: VGG16 and ResNet50."
      ],
      "metadata": {
        "id": "n18ZssAC5UGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports**\n",
        "First, we need to set up our environment and import the necessary libraries."
      ],
      "metadata": {
        "id": "8tR7jjVJ5aRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "QdNnV_0w5ZvL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preparation**\n",
        "\n",
        "I have uploaded the data onto my github, so we will clone the repository and access the dataset from the cloned local repository."
      ],
      "metadata": {
        "id": "Ah6IZTSL5ioS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shravan-18/Deep-Learning-Lab-Resources.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSglbXd5rWk",
        "outputId": "03ac39b5-3dd4-46e9-d8a1-57f2ae258996"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning-Lab-Resources'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 25 (delta 4), reused 22 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (25/25), 19.74 MiB | 44.72 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to unzip the data since I had uploaded it as a zip file. We'll unzip it into the \"/content\" directory"
      ],
      "metadata": {
        "id": "2xo3QKgAVZhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/Deep-Learning-Lab-Resources/Lab-4/Face Images.zip\" -d /content"
      ],
      "metadata": {
        "id": "P5tXCbyfVZM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Data Directory and Parameters"
      ],
      "metadata": {
        "id": "eWzbWgm9ZPwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/Face Images/Final Training Images'\n",
        "batch_size = 32\n",
        "target_size = (224, 224)"
      ],
      "metadata": {
        "id": "clujV87g5nXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data into Training and Validation Sets"
      ],
      "metadata": {
        "id": "LBMjpMW5ZR80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ImageDataGenerators for training and validation\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,  # 20% of the data will be used for validation\n",
        ")\n",
        "\n",
        "datagen_val = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load the training and validation datasets\n",
        "train_dataset = datagen_train.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_dataset = datagen_val.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Display a sample image from the training set\n",
        "def display_sample_images(batch):\n",
        "    images, labels = batch\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_sample_images(next(train_dataset))\n"
      ],
      "metadata": {
        "id": "mKP_p9H8ZtRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample image from the augmented training set\n",
        "def display_augmented_images(batch):\n",
        "    images, labels = batch\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "n0ATnFx4ZxVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ImageDataGenerators for training and validation\n",
        "datagen_train_augment = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,  # 20% of the data will be used for validation\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen_val_augment = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load the training and validation datasets\n",
        "train_dataset_augment = datagen_train_augment.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_dataset_augment = datagen_val_augment.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "display_sample_images(next(train_dataset_augment))"
      ],
      "metadata": {
        "id": "G_ByNg6pZUUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Definition and Training**\n",
        "\n",
        "Without Augmentation"
      ],
      "metadata": {
        "id": "sPnIaJkOJ5Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function makes our lives easier by helping us plot the training curves in one call\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "WTWH3Y1VYlUQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VGG16 model\n",
        "def create_vgg16_model(input_shape, num_classes):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ],
      "metadata": {
        "id": "kkaZ-blU5n5z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = len(train_dataset.class_indices)\n",
        "\n",
        "# Compile and train the VGG16 model\n",
        "vgg16_model = create_vgg16_model(input_shape, num_classes)\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "vgg16_model.summary()"
      ],
      "metadata": {
        "id": "vKE2tTlF5n_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "vgg16_model_history = vgg16_model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fRhKJ06K5oBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet50 model\n",
        "def create_resnet50_model(input_shape, num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ],
      "metadata": {
        "id": "-4pyhL9Y5n75"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the ResNet50 model\n",
        "resnet50_model = create_resnet50_model(input_shape, num_classes)\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.summary()"
      ],
      "metadata": {
        "id": "KsBBGlPf5oEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "resnet50_model_history = resnet50_model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "N5rw1gw4KO97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet50_model_history)"
      ],
      "metadata": {
        "id": "ugT4wfw4YyNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Augmentation"
      ],
      "metadata": {
        "id": "_mkArrw1U2jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the VGG16 model with augmentation\n",
        "vgg16_model_aug = create_vgg16_model(input_shape, num_classes)\n",
        "vgg16_model_aug.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "vgg16_model_aug.fit(train_dataset_augment, epochs=10, validation_data=val_dataset_augment)"
      ],
      "metadata": {
        "id": "NpQIRfniU3Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the ResNet50 model with augmentation\n",
        "resnet50_model_aug = create_resnet50_model(input_shape, num_classes)\n",
        "resnet50_model_aug.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model_aug.fit(train_dataset_augment, epochs=10, validation_data=val_dataset_augment)"
      ],
      "metadata": {
        "id": "Y_rC9jRaU5t_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}