{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Fk1fIRnJqc"
      },
      "source": [
        "# **Ensemble Learning Using Stacking**\n",
        "\n",
        "We will implement stacking ensemble learning with VGG16 and ResNet50 as base models. We will train these models separately and then use their predictions as features for a meta-model (e.g., a logistic regression classifier) to make the final prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0nA_IuynTM4"
      },
      "source": [
        "#### Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv0IdvCXlmKk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_YqWpwenWUB"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD7Y37zkph0I"
      },
      "outputs": [],
      "source": [
        "# Import dataset from kaggle\n",
        "!kaggle datasets download -d smaranjitghose/corn-or-maize-leaf-disease-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh4AevyRpxk0"
      },
      "outputs": [],
      "source": [
        "# Unzip the imported dataset\n",
        "!unzip /content/corn-or-maize-leaf-disease-dataset.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVhgkXMnnXiB"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/data'\n",
        "batch_size = 32\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Define ImageDataGenerators for training and validation\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_dataset = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='training',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "val_dataset = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg8X37vynZ3V"
      },
      "source": [
        "#### Define and Train Base Models\n",
        "\n",
        "Define VGG16 and ResNet50 models with transfer learning and train them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oYc6AhmndDL"
      },
      "outputs": [],
      "source": [
        "def create_base_model(base_model_class, input_shape, num_classes):\n",
        "    base_model = base_model_class(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0rcAPLknfS_"
      },
      "outputs": [],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = len(train_dataset.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6441e36kngcY"
      },
      "outputs": [],
      "source": [
        "# Define models\n",
        "vgg16_model = create_base_model(VGG16, input_shape, num_classes)\n",
        "resnet50_model = create_base_model(ResNet50, input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0fMJZmRPni6h"
      },
      "outputs": [],
      "source": [
        "# Compile and train VGG16 model\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "vgg16_model.fit(train_dataset, epochs=20, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ggFFpaZnkZJ"
      },
      "outputs": [],
      "source": [
        "# Compile and train ResNet50 model\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.fit(train_dataset, epochs=20, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btCGPBYinrM_"
      },
      "source": [
        "#### Extract Features for Stacking\n",
        "\n",
        "Extract features from the base models and prepare the data for the meta-model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3cgrTlonqDg"
      },
      "outputs": [],
      "source": [
        "def extract_features(model, dataset):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for data_batch, label_batch in dataset:\n",
        "        features_batch = model.predict(data_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(label_batch)\n",
        "        if len(features) * dataset.batch_size >= dataset.samples:\n",
        "            break\n",
        "    return np.vstack(features), np.concatenate(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vH6JeeUnwPd"
      },
      "outputs": [],
      "source": [
        "# Extract features\n",
        "vgg16_features, vgg16_labels = extract_features(vgg16_model, train_dataset)\n",
        "resnet50_features, resnet50_labels = extract_features(resnet50_model, train_dataset)\n",
        "\n",
        "# Stack features\n",
        "X_train_stacked = np.hstack((vgg16_features, resnet50_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2zSkCtCnyYH"
      },
      "outputs": [],
      "source": [
        "# Extract validation features\n",
        "vgg16_val_features, vgg16_val_labels = extract_features(vgg16_model, val_dataset)\n",
        "resnet50_val_features, resnet50_val_labels = extract_features(resnet50_model, val_dataset)\n",
        "\n",
        "# Stack validation features\n",
        "X_val_stacked = np.hstack((vgg16_val_features, resnet50_val_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-rmWCZWn3nN"
      },
      "outputs": [],
      "source": [
        "# Ensure labels match\n",
        "assert np.array_equal(vgg16_labels, resnet50_labels)\n",
        "assert np.array_equal(vgg16_val_labels, resnet50_val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyFElgvVn32R"
      },
      "source": [
        "#### Train Meta-Model\n",
        "Train a logistic regression classifier as the meta-model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NzY_Mf8n5lr"
      },
      "outputs": [],
      "source": [
        "# Train-test split for meta-model\n",
        "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(\n",
        "    X_train_stacked, vgg16_labels, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOldxZNUn-Cl"
      },
      "outputs": [],
      "source": [
        "# Define and train meta-model\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "meta_model.fit(X_train_meta, y_train_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNwCb2yAn_eP"
      },
      "outputs": [],
      "source": [
        "# Evaluate meta-model\n",
        "y_pred_meta = meta_model.predict(X_test_meta)\n",
        "print(f'Logistic Regression Meta-Model Accuracy: {accuracy_score(y_test_meta, y_pred_meta)}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}