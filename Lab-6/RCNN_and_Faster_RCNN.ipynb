{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Fast RCNN\n",
        "\n",
        "Fast RCNN is a significant improvement over RCNN as it processes the entire image at once and then applies RoI (Region of Interest) pooling to extract features for region proposals. This reduces computational redundancy by running the CNN only once for the entire image.\n",
        "\n",
        "#### Key Steps:\n",
        "\n",
        "1. **Backbone Network (VGG16)**:\n",
        "   - A pre-trained VGG16 is used as the backbone to extract feature maps from the entire image. The image is passed once through the convolutional layers, generating feature maps.\n",
        "\n",
        "2. **RoI Pooling**:\n",
        "   - RoI Pooling is used to convert the feature maps of each proposed region into a fixed size (e.g., 7x7). This allows the Fast RCNN to process regions of varying sizes.\n",
        "   - The proposed regions (RoIs) are provided as input coordinates.\n",
        "\n",
        "3. **Fully Connected Layers**:\n",
        "   - After RoI pooling, the pooled features are flattened and passed through two fully connected layers to generate high-level features for classification and bounding box regression.\n",
        "\n",
        "4. **Classification and Bounding Box Regression**:\n",
        "   - The features are passed through two output heads:\n",
        "     - A softmax classifier that assigns a class label to the region.\n",
        "     - A bounding box regressor that refines the region's coordinates.\n",
        "     \n",
        "5. **Training**:\n",
        "   - Fast RCNN is trained using a multi-task loss function that combines classification loss (softmax) and bounding box regression loss.\n",
        "\n",
        "#### Limitations:\n",
        "- Fast RCNN still relies on an external region proposal algorithm (e.g., Selective Search), which is not optimized and slows down the overall speed.\n"
      ],
      "metadata": {
        "id": "LM4nmPmp1T_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XklGXImG1S4F"
      },
      "outputs": [],
      "source": [
        "# Example Implementation of Fast RCNN is as follows\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fast R-CNN model\n",
        "class FastRCNN(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FastRCNN, self).__init__()\n",
        "        # Feature extractor (backbone)\n",
        "        self.backbone = tf.keras.applications.VGG16(include_top=False, input_shape=(None, None, 3))\n",
        "        self.roi_pooling = tf.keras.layers.MaxPool2D(pool_size=(7, 7))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(4096, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(4096, activation='relu')\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        self.bbox_regressor = tf.keras.layers.Dense(num_classes * 4, activation='linear')  # 4 bbox coordinates per class\n",
        "\n",
        "    def call(self, inputs, rois):\n",
        "        feature_map = self.backbone(inputs)\n",
        "\n",
        "        pooled_regions = []\n",
        "        for roi in rois:\n",
        "            pooled = self.roi_pooling(feature_map[:, roi[0]:roi[2], roi[1]:roi[3], :])\n",
        "            pooled_regions.append(pooled)\n",
        "\n",
        "        x = tf.concat(pooled_regions, axis=0)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        classification = self.classifier(x)\n",
        "        bbox_regression = self.bbox_regressor(x)\n",
        "\n",
        "        return classification, bbox_regression\n",
        "\n",
        "# Example usage\n",
        "def fast_rcnn_pipeline(image, rois):\n",
        "    model = FastRCNN(num_classes=21)  # For 20 classes + background (VOC example)\n",
        "    classification, bbox_regression = model(image, rois)\n",
        "    return classification, bbox_regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The following is a test to check if the Fast RCNN model completes 1 forward pass. You can use such tests to check if your model works initially.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a random constant image of shape (1, 224, 224, 3) (batch_size=1)\n",
        "random_image = tf.constant(np.random.random((1, 224, 224, 3)), dtype=tf.float32)\n",
        "\n",
        "# Create random RoIs (Region of Interest) - [x_min, y_min, x_max, y_max]\n",
        "random_rois = tf.constant([[50, 30, 170, 150]], dtype=tf.int32)  # Example 1 random RoI\n",
        "\n",
        "# Instantiate the Fast RCNN model (example, number of classes = 21)\n",
        "model = FastRCNN(num_classes=21)\n",
        "\n",
        "# Forward pass through the Fast RCNN model\n",
        "classification, bbox_regression = model(random_image, random_rois)\n",
        "\n",
        "# Assertions to check the output shape\n",
        "assert classification.shape[0] == random_rois.shape[0], \"Classification output mismatch\"\n",
        "assert bbox_regression.shape[0] == random_rois.shape[0], \"Bounding box output mismatch\"\n",
        "\n",
        "# Print success message if assertions pass\n",
        "print(\"Fast RCNN forward pass successful!\")\n",
        "print(\"Classification Output Shape:\", classification.shape)\n",
        "print(\"Bounding Box Regression Output Shape:\", bbox_regression.shape)"
      ],
      "metadata": {
        "id": "w1eB2cnG16Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Faster RCNN\n",
        "\n",
        "Faster RCNN is an extension of Fast RCNN that integrates the Region Proposal Network (RPN) into the model itself, making region proposal generation a learnable process. This removes the reliance on external region proposal methods like Selective Search and significantly speeds up the detection pipeline.\n",
        "\n",
        "#### Key Components:\n",
        "\n",
        "1. **Backbone Network (ResNet50)**:\n",
        "   - The entire image is first passed through a pre-trained convolutional backbone (e.g., ResNet50) to generate feature maps.\n",
        "\n",
        "2. **Region Proposal Network (RPN)**:\n",
        "   - RPN is a small network that slides over the feature maps generated by the backbone.\n",
        "   - It predicts two things for each anchor:\n",
        "     - Objectness score: Whether the anchor contains an object (foreground) or background.\n",
        "     - Bounding box deltas: Adjustments to the anchor coordinates to refine the proposal.\n",
        "   - RPN outputs a set of refined region proposals (RoIs).\n",
        "\n",
        "3. **RoI Align**:\n",
        "   - Similar to RoI Pooling in Fast RCNN, but uses RoI Align for more accurate feature extraction.\n",
        "   - RoI Align fixes the misalignment issues caused by quantization in RoI Pooling by avoiding any rounding of floating-point RoI coordinates.\n",
        "\n",
        "4. **Classification and Bounding Box Regression**:\n",
        "   - After RoI Align, the features for each proposal are flattened and passed through two fully connected layers.\n",
        "   - Similar to Fast RCNN, the features are then used for:\n",
        "     - **Classification**: Assign a class label to the region.\n",
        "     - **Bounding Box Regression**: Refine the bounding box coordinates.\n",
        "\n",
        "5. **Training**:\n",
        "   - The model is trained with a multi-task loss that combines:\n",
        "     - **RPN Loss**: Loss for objectness and bounding box regression from RPN.\n",
        "     - **Fast RCNN Loss**: Loss for classification and bounding box regression of the final detections.\n",
        "\n",
        "#### Advantages:\n",
        "- **End-to-End Training**: The RPN is trained jointly with the rest of the network, making the region proposal process more efficient.\n",
        "- **Faster**: Since RPN is integrated within the network, Faster RCNN is much faster than Fast RCNN, especially when processing large datasets."
      ],
      "metadata": {
        "id": "gS0ahJSW1e31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Region Proposal Network (RPN) module\n",
        "class RPN(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_anchors):\n",
        "        super(RPN, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.cls_layer = tf.keras.layers.Conv2D(num_anchors * 2, (1, 1))  # Binary classification (object/no object)\n",
        "        self.reg_layer = tf.keras.layers.Conv2D(num_anchors * 4, (1, 1))  # 4 coordinates for each anchor\n",
        "\n",
        "    def call(self, feature_map):\n",
        "        x = self.conv(feature_map)\n",
        "        cls_logits = self.cls_layer(x)\n",
        "        reg_deltas = self.reg_layer(x)\n",
        "        return cls_logits, reg_deltas\n",
        "\n",
        "# Faster R-CNN with RPN and RoI Align (for feature extraction and pooling)\n",
        "class FasterRCNN(tf.keras.Model):\n",
        "    def __init__(self, num_classes, num_anchors):\n",
        "        super(FasterRCNN, self).__init__()\n",
        "        # Backbone network (feature extractor)\n",
        "        self.backbone = tf.keras.applications.ResNet50(include_top=False, input_shape=(None, None, 3))\n",
        "        # Region Proposal Network (RPN)\n",
        "        self.rpn = RPN(num_anchors)\n",
        "        # RoI Pooling\n",
        "        self.roi_align = tf.keras.layers.MaxPool2D(pool_size=(7, 7))\n",
        "        # Fully connected layers for classification and bounding box regression\n",
        "        self.fc1 = tf.keras.layers.Dense(4096, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(4096, activation='relu')\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        self.bbox_regressor = tf.keras.layers.Dense(num_classes * 4, activation='linear')\n",
        "\n",
        "    def call(self, inputs, rois):\n",
        "        feature_map = self.backbone(inputs)\n",
        "        rpn_cls_logits, rpn_bbox_deltas = self.rpn(feature_map)\n",
        "\n",
        "        pooled_regions = []\n",
        "        for roi in rois:\n",
        "            pooled = self.roi_align(feature_map[:, roi[0]:roi[2], roi[1]:roi[3], :])\n",
        "            pooled_regions.append(pooled)\n",
        "\n",
        "        x = tf.concat(pooled_regions, axis=0)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        classification = self.classifier(x)\n",
        "        bbox_regression = self.bbox_regressor(x)\n",
        "\n",
        "        return classification, bbox_regression, rpn_cls_logits, rpn_bbox_deltas\n",
        "\n",
        "# Example usage\n",
        "def faster_rcnn_pipeline(image, rois):\n",
        "    model = FasterRCNN(num_classes=21, num_anchors=9)  # VOC-like dataset with 9 anchors\n",
        "    classification, bbox_regression, rpn_cls_logits, rpn_bbox_deltas = model(image, rois)\n",
        "    return classification, bbox_regression, rpn_cls_logits, rpn_bbox_deltas"
      ],
      "metadata": {
        "id": "y-t8yiNf1e-3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The following is a test to check if the Faster RCNN model completes 1 forward pass. You can use such tests to check if your model works initially.\n",
        "'''\n",
        "\n",
        "\n",
        "# Create a random constant image of shape (1, 224, 224, 3) (batch_size=1)\n",
        "random_image = tf.constant(np.random.random((1, 224, 224, 3)), dtype=tf.float32)\n",
        "\n",
        "# Create random RoIs (Region of Interest) - [x_min, y_min, x_max, y_max]\n",
        "random_rois = tf.constant([[50, 30, 170, 150]], dtype=tf.int32)  # Example 1 random RoI\n",
        "\n",
        "# Instantiate the Faster RCNN model (example, number of classes = 21 and anchors = 9)\n",
        "model = FasterRCNN(num_classes=21, num_anchors=9)\n",
        "\n",
        "# Forward pass through the Faster RCNN model\n",
        "classification, bbox_regression, rpn_cls_logits, rpn_bbox_deltas = model(random_image, random_rois)\n",
        "\n",
        "# Assertions to check output shapes\n",
        "assert classification.shape[0] == random_rois.shape[0], \"Classification output mismatch\"\n",
        "assert bbox_regression.shape[0] == random_rois.shape[0], \"Bounding box output mismatch\"\n",
        "assert rpn_cls_logits.shape[0] == random_image.shape[0], \"RPN classification logits output mismatch\"\n",
        "assert rpn_bbox_deltas.shape[0] == random_image.shape[0], \"RPN bounding box deltas output mismatch\"\n",
        "\n",
        "# Print success message if assertions pass\n",
        "print(\"Faster RCNN forward pass successful!\")\n",
        "print(\"Classification Output Shape:\", classification.shape)\n",
        "print(\"Bounding Box Regression Output Shape:\", bbox_regression.shape)\n",
        "print(\"RPN Classification Logits Output Shape:\", rpn_cls_logits.shape)\n",
        "print(\"RPN Bounding Box Deltas Output Shape:\", rpn_bbox_deltas.shape)"
      ],
      "metadata": {
        "id": "q78CrLAl2gDv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}